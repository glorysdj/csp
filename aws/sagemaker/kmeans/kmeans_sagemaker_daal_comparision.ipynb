{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker, DAAL Comparsion with MNIST, Synthetic Datasets (0.5Mx20 and 4.8Mx20)\n",
    "\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "\n",
    "2. [MNIST Example: 50Kx784, k=10](#MNIST-Example:-50Kx784,-k=10)\n",
    "    1. [Data Prep](#Data-Prep)\n",
    "    2. [Sagemaker Training Setup]\n",
    "    3. [Start Sagemaker Training]\n",
    "    4. [Download Sagemaker Trained Model and Compute Accuracy]\n",
    "    5. [Intel DAAL Kmeans with MNIST ]\n",
    "    6. [Data Prep]\n",
    "    7. [DAAL Training Setup]\n",
    "    8. [Start DAAL Training]\n",
    "    9. [Download DAAL Trained Model and Compute Accuracy]\n",
    "    10.[MNIST Summary]\n",
    "\n",
    "2. [Synthetic Dataset 1: 0.5Mx20, k=20]\n",
    "    1. [Data Prep]\n",
    "    2. [Sagemaker Training Setup]\n",
    "    3. [Start Sagemaker Training]\n",
    "    4. [Intel DAAL Kmeans with 0.5Mx20 Synthetic Dataset ]\n",
    "    5. [Data Prep]\n",
    "    6. [DAAL Training Setup]\n",
    "    7. [Start DAAL Training]\n",
    "    8. [Synthetic Dataset 1 (0.5Mx20) Summary]\n",
    "\n",
    "3. [Synthetic Dataset 2: 4.8Mx31, k=20]\n",
    "    1. [Data Prep]\n",
    "    2. [Sagemaker Training Setup]\n",
    "    3. [Start Sagemaker Training]\n",
    "    4. [Intel DAAL Kmeans with 4.8Mx31 Synthetic Dataset ]\n",
    "    5. [Data Prep]\n",
    "    6. [DAAL Training Setup]\n",
    "    7. [Start DAAL Training]\n",
    "    8. [Synthetic Dataset 1 (4.8Mx31) Summary]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this we compare KMeans algorithm implemented in Sagemaker and Intel DAAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.18.4)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (1.14.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2018.8.24)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Example: 50Kx784, k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "\n",
    "Next, we read the dataset from the existing repository into memory, for preprocessing prior to training.  In this case we'll use the MNIST dataset, which contains 70K 28 x 28 pixel images of handwritten digits.  For more details, please see [here](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 952 ms, sys: 284 ms, total: 1.24 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle, gzip, urllib.request\n",
    "\n",
    "# Load the dataset\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://rpanchum/kmeans_sm_mnist/\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'rpanchum' \n",
    "sm_mnist_data_key = 'kmeans_sm_mnist/'\n",
    "sm_mnist_data_location = 's3://{}/{}'.format(bucket_name, sm_mnist_data_key)\n",
    "sm_mnist_output_location = 's3://{}/{}'.format(bucket_name, sm_mnist_data_key)\n",
    "\n",
    "print('training artifacts will be uploaded to: {}'.format(sm_mnist_output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RecordSet format of training data as required by SM Kmeans...\n",
      "(<class 'sagemaker.amazon.amazon_estimator.RecordSet'>, {'s3_data': 's3://rpanchum/kmeans_sm_mnist/KMeans-2018-09-28-19-38-15-773/.amazon.manifest', 'feature_dim': 784, 'num_records': 50000, 's3_data_type': 'ManifestFile', 'channel': 'train'})\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import KMeans\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm_kmeans = KMeans(role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.18xlarge',\n",
    "                    output_path=sm_mnist_output_location,\n",
    "                    k=10,\n",
    "                    center_factor=1,\n",
    "                    init_method='kmeans++',\n",
    "                    max_iterations=50,\n",
    "                    data_location=sm_mnist_data_location)\n",
    "\n",
    "print ('Building RecordSet format of training data as required by SM Kmeans...')\n",
    "sm_kmeans_records = sm_kmeans.record_set(train_set[0])\n",
    "print (sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Sagemaker Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kmeans-2018-09-28-19-38-26-129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 19:38:26 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-09-28 19:40:06 Downloading - Downloading input data\n",
      "2018-09-28 19:40:12 Training - Downloading the training image..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'k': u'10', u'force_dense': u'True', u'init_method': u'kmeans++', u'feature_dim': u'784', u'local_lloyd_max_iter': u'50', u'extra_center_factor': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'50', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 WARNING 140275552188224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Using default worker.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Create Store: local\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] nvidia-smi took: 0.0251710414886 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'50', u'_kvstore': u'auto', u'k': u'10', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:172: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:122: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:40 INFO 140275552188224] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1538163640.789976, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538163640.789937}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] processed a total of 50000 examples\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 50000, \"sum\": 50000.0, \"min\": 50000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}, \"Total Records Seen\": {\"count\": 1, \"max\": 55000, \"sum\": 55000.0, \"min\": 55000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 50000, \"sum\": 50000.0, \"min\": 50000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1538163641.174569, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1538163640.790263}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] #throughput_metric: host=algo-1, train throughput=130073.200412 records/second\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 WARNING 140275552188224] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] shrinking 10 centers into 10\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #0. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #1. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #2. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #3. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #4. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #5. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #6. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #7. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #8. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] local kmeans attempt #9. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] finished shrinking process. Mean Square Distance = 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] #quality_metric: host=algo-1, train msd <loss>=2.07325669521e-07\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] batch data loading with context took: 83.7340%, (0.320975 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] compute all data-center distances: point norm took: 7.4014%, (0.028371 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] gradient: cluster center took: 2.7326%, (0.010475 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] predict compute msd took: 1.9154%, (0.007342 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] compute all data-center distances: inner product took: 0.9644%, (0.003697 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] update state and report convergance took: 0.9094%, (0.003486 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] collect from kv store took: 0.6631%, (0.002542 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] gradient: one_hot took: 0.5199%, (0.001993 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] splitting centers key-value pair took: 0.4250%, (0.001629 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] compute all data-center distances: center norm took: 0.3431%, (0.001315 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] gradient: cluster size  took: 0.3142%, (0.001204 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] predict minus dist took: 0.0492%, (0.000189 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] update set-up time took: 0.0282%, (0.000108 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] TOTAL took: 0.383326292038\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 172.28317260742188, \"sum\": 172.28317260742188, \"min\": 172.28317260742188}, \"initialize.time\": {\"count\": 1, \"max\": 42.3579216003418, \"sum\": 42.3579216003418, \"min\": 42.3579216003418}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.22482872009277344, \"sum\": 0.22482872009277344, \"min\": 0.22482872009277344}, \"update.time\": {\"count\": 1, \"max\": 384.1710090637207, \"sum\": 384.1710090637207, \"min\": 384.1710090637207}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.30493736267089844, \"sum\": 0.30493736267089844, \"min\": 0.30493736267089844}, \"_shrink.time\": {\"count\": 1, \"max\": 171.2958812713623, \"sum\": 171.2958812713623, \"min\": 171.2958812713623}}, \"EndTime\": 1538163641.347748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538163640.705534}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:40:41 INFO 140275552188224] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 704.1361331939697, \"sum\": 704.1361331939697, \"min\": 704.1361331939697}, \"setuptime\": {\"count\": 1, \"max\": 10.044097900390625, \"sum\": 10.044097900390625, \"min\": 10.044097900390625}}, \"EndTime\": 1538163641.351502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538163641.347834}\n",
      "\u001b[0m\n",
      "\n",
      "2018-09-28 19:40:44 Uploading - Uploading generated training model\n",
      "2018-09-28 19:40:49 Completed - Training job completed\n",
      "Billable seconds: 44\n",
      "CPU times: user 300 ms, sys: 44 ms, total: 344 ms\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_kmeans.fit(sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  kmeans-2018-09-28-19-38-26-129\n",
      "Model saved at:  s3://rpanchum/kmeans_sm_mnist/kmeans-2018-09-28-19-38-26-129/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", sm_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", sm_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Sagemaker Trained Model and Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the model saved at:  s3://rpanchum/kmeans_sm_mnist/kmeans-2018-09-28-19-38-26-129/output/model.tar.gz\n",
      "MNIST SM centroids shape:  (10, 784)\n"
     ]
    }
   ],
   "source": [
    "import os, boto3\n",
    "import mxnet as mx\n",
    "\n",
    "sm_mnist_model_key = sm_mnist_data_key + sm_kmeans.latest_training_job.name + '/output/model.tar.gz'\n",
    "print ('Downloading the model saved at: ', sm_kmeans.model_data)\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(sm_mnist_model_key, 'sm_model.tar.gz')\n",
    "\n",
    "os.system('tar -zxf sm_model.tar.gz && unzip model_algo-1')\n",
    "\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')\n",
    "sagemaker_centroids=Kmeans_model_params[0].asnumpy()\n",
    "print('MNIST SM centroids shape: ', sagemaker_centroids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM Accuracy on MNIST Train Set:  0.35307083305090553\n",
      "SM Accuracy on MNIST Test Set:  0.3718264677316023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "sklearn_kmeans = KMeans(10)\n",
    "sklearn_kmeans.cluster_centers_ = sagemaker_centroids\n",
    "\n",
    "sm_mnist_train_assignments=sklearn_kmeans.predict(train_set[0])\n",
    "sm_mnist_test_assignments=sklearn_kmeans.predict(test_set[0])\n",
    "\n",
    "print(\"SM Accuracy on MNIST Train Set: \", str(v_measure_score(train_set[1], sm_mnist_train_assignments)))\n",
    "print(\"SM Accuracy on MNIST Test Set: \" , str(v_measure_score(test_set[1], sm_mnist_test_assignments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel DAAL Kmeans with MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt(\"train_data.csv\", train_set[0], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded at: s3://rpanchum/kmeans_daal_mnist\n"
     ]
    }
   ],
   "source": [
    "training_data_file = 'train_data.csv'\n",
    "daal_mnist_data_key = 'kmeans_daal_mnist'\n",
    "daal_mnist_output_location = 's3://{}/{}'.format(bucket_name, daal_mnist_data_key)\n",
    "\n",
    "print (\"Training artifacts will be uploaded at: \" + daal_mnist_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAL Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "daal_mnist_data_location = sess.upload_data(training_data_file, bucket=bucket_name, key_prefix=daal_mnist_data_key)\n",
    "\n",
    "daal_kmeans_image = '927702822156.dkr.ecr.us-west-2.amazonaws.com/daal-kmeans-sample:latest'\n",
    "\n",
    "daal_kmeans = sage.estimator.Estimator(image_name=daal_kmeans_image,\n",
    "                                       role=role,\n",
    "                                       train_instance_count=1,\n",
    "                                       train_instance_type='ml.c5.18xlarge',\n",
    "                                       output_path=daal_mnist_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       hyperparameters={'nClusters': 10,\n",
    "                                                        'initialCentroidMethod': 'plusPlusDense',\n",
    "                                                        'maxIterations': 50 } \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start DAAL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: daal-kmeans-sample-2018-09-28-19-42-47-284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 19:42:47 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-09-28 19:44:35 Downloading - Downloading input data...\n",
      "2018-09-28 19:44:53 Training - Downloading the training image...\n",
      "Training image download completed. Training in progress..\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     Container setup completed, In Docker entrypoint - train... \u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     Default Hyperparameters loaded: \u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': 'defaultDense',\n",
      " 'maxIterations': 300,\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': 2,\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     Updated with user hyperparameters, Final Hyperparameters: \u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': u'plusPlusDense',\n",
      " 'maxIterations': u'50',\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': u'10',\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:44 INFO     Reading training data... \u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:54 INFO     Training Data Shape: (50000, 784)\u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:54 INFO     Starting DAAL Kmeans training...\u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:55 INFO     Training time in sec = 0.572371959686\u001b[0m\n",
      "\u001b[31m2018-09-28 19:45:55 INFO     Model saved at <open file '/opt/ml/model/daal-kmeans-model.npy', mode 'w' at 0x7fae330e4270>\u001b[0m\n",
      "\n",
      "2018-09-28 19:45:59 Uploading - Uploading generated training model\n",
      "2018-09-28 19:46:04 Completed - Training job completed\n",
      "Billable seconds: 90\n",
      "CPU times: user 420 ms, sys: 28 ms, total: 448 ms\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daal_kmeans.fit(daal_mnist_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  daal-kmeans-sample-2018-09-28-19-42-47-284\n",
      "Model saved at:  s3://rpanchum/kmeans_daal_mnist/daal-kmeans-sample-2018-09-28-19-42-47-284/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", daal_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", daal_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download DAAL Trained Model and Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the model saved at:  s3://rpanchum/kmeans_daal_mnist/daal-kmeans-sample-2018-09-28-19-42-47-284/output/model.tar.gz\n",
      "kmeans_daal_mnist/daal-kmeans-sample-2018-09-28-19-42-47-284/output/model.tar.gz\n",
      "MNIST DAAL centroids shape:  (10, 784)\n"
     ]
    }
   ],
   "source": [
    "import os, boto3\n",
    "\n",
    "daal_mnist_model_key = daal_mnist_data_key + \"/\" + daal_kmeans.latest_training_job.name + '/output/model.tar.gz'\n",
    "print ('Downloading the model saved at: ', daal_kmeans.model_data)\n",
    "print(daal_mnist_model_key)\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(daal_mnist_model_key, 'daal_model.tar.gz')\n",
    "\n",
    "os.system('tar -zxf daal_model.tar.gz')\n",
    "daal_centroids, daal_assignments = np.load(\"daal-kmeans-model.npy\", encoding = 'latin1')\n",
    "print('MNIST DAAL centroids shape: ', daal_centroids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAAL Accuracy on MNIST Train Set:  0.4937834635054327\n",
      "DAAL Accuracy on MNIST Test Set:  0.5073462004406061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "sklearn_kmeans = KMeans(10)\n",
    "sklearn_kmeans.cluster_centers_ = daal_centroids\n",
    "\n",
    "daal_mnist_train_assignments=sklearn_kmeans.predict(train_set[0])\n",
    "daal_mnist_test_assignments=sklearn_kmeans.predict(test_set[0])\n",
    "\n",
    "print(\"DAAL Accuracy on MNIST Train Set: \", str(v_measure_score(train_set[1], daal_mnist_train_assignments)))\n",
    "print(\"DAAL Accuracy on MNIST Test Set: \" , str(v_measure_score(test_set[1], daal_mnist_test_assignments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Summary\n",
    "k=10, maxIterations=50 \n",
    "\n",
    "Sagemaker Training Time Only: 0.38 sec  \n",
    "DAAL Training Time Only: 0.57 sec  \n",
    "\n",
    "Sagemaker MNIST Test Accuracy: 37.1%  \n",
    "DAAL MNIST Test Accuracy: 50.7%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset 1: 0.5Mx20, k=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-28 19:46:30--  https://s3-us-west-2.amazonaws.com/rpanchum/kmeans_datasets/0.5Mx20/mlsd2_500000_20_20.csv\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.248.120\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.248.120|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 105000000 (100M) [text/csv]\n",
      "Saving to: ‘mlsd2_500000_20_20.csv.3’\n",
      "\n",
      "mlsd2_500000_20_20. 100%[===================>] 100.14M  86.2MB/s    in 1.2s    \n",
      "\n",
      "2018-09-28 19:46:32 (86.2 MB/s) - ‘mlsd2_500000_20_20.csv.3’ saved [105000000/105000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O mlsd2_500000_20_20.csv https://s3-us-west-2.amazonaws.com/rpanchum/kmeans_datasets/0.5Mx20/mlsd2_500000_20_20.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0              1              2              3   \\\n",
      "count  500000.000000  500000.000000  500000.000000  500000.000000   \n",
      "mean       54.440392      55.849094      57.122341      57.997566   \n",
      "std        17.286438      15.576500      18.243711      18.005829   \n",
      "min        24.709999      20.190001      22.700001      20.540001   \n",
      "25%        36.709999      43.220001      42.349998      42.750000   \n",
      "50%        54.250000      53.299999      61.349998      60.150002   \n",
      "75%        71.160004      70.860001      72.519997      74.239998   \n",
      "max        91.169998      89.129997      89.080002      92.459999   \n",
      "\n",
      "                  4              5              6              7   \\\n",
      "count  500000.000000  500000.000000  500000.000000  500000.000000   \n",
      "mean       54.450413      56.562336      55.726784      56.136658   \n",
      "std        17.778864      18.171492      16.956083      17.414059   \n",
      "min        24.790001      22.330000      24.530001      21.500000   \n",
      "25%        35.520000      40.430000      38.070000      41.700001   \n",
      "50%        54.790001      57.029999      58.360001      54.419998   \n",
      "75%        71.910004      74.930000      66.849998      70.160004   \n",
      "max        87.940002      90.889999      93.540001      88.580002   \n",
      "\n",
      "                  8              9       ...                   11  \\\n",
      "count  500000.000000  500000.000000      ...        500000.000000   \n",
      "mean       58.001858      57.554466      ...            56.614548   \n",
      "std        17.884829      18.064907      ...            18.208382   \n",
      "min        20.639999      22.379999      ...            16.770000   \n",
      "25%        40.740002      38.320000      ...            44.040001   \n",
      "50%        57.369999      63.900002      ...            57.400002   \n",
      "75%        73.769997      72.779999      ...            74.169998   \n",
      "max        89.330002      89.099998      ...            89.000000   \n",
      "\n",
      "                  12             13             14             15  \\\n",
      "count  500000.000000  500000.000000  500000.000000  500000.000000   \n",
      "mean       56.065472      55.268497      54.390404      55.317017   \n",
      "std        17.797192      17.149839      16.534781      17.437401   \n",
      "min        23.430000      20.219999      21.900000      17.139999   \n",
      "25%        38.160000      40.299999      40.540001      40.080002   \n",
      "50%        58.509998      55.470001      56.060001      55.410000   \n",
      "75%        71.449997      67.820000      67.599998      72.510002   \n",
      "max        86.059998      91.410004      88.980003      88.809998   \n",
      "\n",
      "                  16             17             18             19  \\\n",
      "count  500000.000000  500000.000000  500000.000000  500000.000000   \n",
      "mean       56.693531      56.077961      56.570129      56.536282   \n",
      "std        18.698183      16.253635      18.216196      17.865135   \n",
      "min        20.910000      21.379999      24.120001      18.370001   \n",
      "25%        39.270000      41.490002      39.730000      39.380001   \n",
      "50%        61.230000      56.549999      57.840000      56.000000   \n",
      "75%        74.180000      68.980003      73.889999      73.510002   \n",
      "max        89.910004      88.830002      95.379997      91.419998   \n",
      "\n",
      "                  20  \n",
      "count  500000.000000  \n",
      "mean       42.694263  \n",
      "std        25.688370  \n",
      "min         1.000000  \n",
      "25%        20.000000  \n",
      "50%        44.000000  \n",
      "75%        67.000000  \n",
      "max        84.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "Training data shape:  (500000, 21)\n",
      "CPU times: user 2.1 s, sys: 124 ms, total: 2.22 s\n",
      "Wall time: 8.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file_0_5Mx20 = \"mlsd2_500000_20_20.csv\"\n",
    "data = pd.read_csv(input_file_0_5Mx20, header=None, dtype=np.float32)\n",
    "print(data.describe())\n",
    "\n",
    "train_set = np.array(data)\n",
    "print (\"Training data shape: \", train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://rpanchum/kmeans_sm_0.5Mx20\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'rpanchum' \n",
    "sm_0_5Mx20_data_key = 'kmeans_sm_0.5Mx20'\n",
    "sm_0_5Mx20_data_location = 's3://{}/{}'.format(bucket_name, sm_0_5Mx20_data_key)\n",
    "sm_0_5Mx20_output_location = 's3://{}/{}'.format(bucket_name, sm_0_5Mx20_data_key)\n",
    "\n",
    "print('training artifacts will be uploaded to: {}'.format(sm_0_5Mx20_output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RecordSet format of training data as required by SM Kmeans...\n",
      "(<class 'sagemaker.amazon.amazon_estimator.RecordSet'>, {'s3_data': 's3://rpanchum/kmeans_sm_0.5Mx20/KMeans-2018-09-28-19-46-41-600/.amazon.manifest', 'feature_dim': 21, 'num_records': 500000, 's3_data_type': 'ManifestFile', 'channel': 'train'})\n",
      "CPU times: user 17.3 s, sys: 256 ms, total: 17.6 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker import KMeans\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm_kmeans = KMeans(role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.18xlarge',\n",
    "                    output_path=sm_0_5Mx20_output_location,\n",
    "                    k=20,\n",
    "                    center_factor=1,\n",
    "                    init_method='kmeans++',\n",
    "                    max_iterations=100,\n",
    "                    data_location=sm_0_5Mx20_data_location)\n",
    "\n",
    "print ('Building RecordSet format of training data as required by SM Kmeans...')\n",
    "sm_kmeans_records = sm_kmeans.record_set(train_set)\n",
    "print (sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Sagemaker Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kmeans-2018-09-28-19-46-56-381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 19:46:56 Starting - Starting the training job...\n",
      "Launching requested ML instances...\n",
      "Preparing the instances for training......\n",
      "2018-09-28 19:48:52 Downloading - Downloading input data...\n",
      "2018-09-28 19:48:58 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'k': u'20', u'force_dense': u'True', u'init_method': u'kmeans++', u'feature_dim': u'21', u'local_lloyd_max_iter': u'100', u'extra_center_factor': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'21', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'100', u'_kvstore': u'auto', u'k': u'20', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 WARNING 140644009961280] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Using default worker.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Create Store: local\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] nvidia-smi took: 0.0251860618591 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:28 INFO 140644009961280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'21', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'100', u'_kvstore': u'auto', u'k': u'20', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:172: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:122: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1538164169.03804, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164169.038011}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 10: Short term msd 8898.291639. Long term msd 11799.410366\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 20: Short term msd 6407.048070. Long term msd 7555.007837\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 30: Short term msd 6686.927233. Long term msd 6902.818212\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 40: Short term msd 6387.485396. Long term msd 6509.900705\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 50: Short term msd 6971.244402. Long term msd 6838.390760\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 60: Short term msd 7488.211935. Long term msd 7234.958202\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 70: Short term msd 7338.151632. Long term msd 7290.489495\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 80: Short term msd 7462.509270. Long term msd 7462.531675\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Iter 90: Short term msd 8044.846253. Long term msd 7880.462313\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] processed a total of 500000 examples\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 500000, \"sum\": 500000.0, \"min\": 500000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 101, \"sum\": 101.0, \"min\": 101}, \"Total Records Seen\": {\"count\": 1, \"max\": 505000, \"sum\": 505000.0, \"min\": 505000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 500000, \"sum\": 500000.0, \"min\": 500000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1538164169.739237, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1538164169.038256}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] #throughput_metric: host=algo-1, train throughput=713165.883556 records/second\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 WARNING 140644009961280] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] shrinking 20 centers into 20\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #0. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #1. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #2. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #3. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #4. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #5. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #6. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #7. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #8. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] local kmeans attempt #9. Current mean square distance 0.000000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] finished shrinking process. Mean Square Distance = 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] #quality_metric: host=algo-1, train msd <loss>=1.52132262343e-08\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] batch data loading with context took: 70.0010%, (0.486420 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] predict compute msd took: 8.6620%, (0.060190 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] gradient: cluster center took: 6.4905%, (0.045101 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] update state and report convergance took: 3.1959%, (0.022207 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] gradient: one_hot took: 1.9993%, (0.013892 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] compute all data-center distances: point norm took: 1.9621%, (0.013634 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] compute all data-center distances: inner product took: 1.9592%, (0.013614 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] collect from kv store took: 1.8278%, (0.012701 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] gradient: cluster size  took: 1.6983%, (0.011801 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] splitting centers key-value pair took: 1.0381%, (0.007213 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] compute all data-center distances: center norm took: 0.9867%, (0.006856 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] predict minus dist took: 0.1654%, (0.001149 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] update set-up time took: 0.0138%, (0.000096 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] TOTAL took: 0.694875955582\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 210.6790542602539, \"sum\": 210.6790542602539, \"min\": 210.6790542602539}, \"initialize.time\": {\"count\": 1, \"max\": 36.32211685180664, \"sum\": 36.32211685180664, \"min\": 36.32211685180664}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15687942504882812, \"sum\": 0.15687942504882812, \"min\": 0.15687942504882812}, \"update.time\": {\"count\": 1, \"max\": 700.8359432220459, \"sum\": 700.8359432220459, \"min\": 700.8359432220459}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.2048015594482422, \"sum\": 0.2048015594482422, \"min\": 0.2048015594482422}, \"_shrink.time\": {\"count\": 1, \"max\": 209.91897583007812, \"sum\": 209.91897583007812, \"min\": 209.91897583007812}}, \"EndTime\": 1538164169.950585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164168.982975}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:49:29 INFO 140644009961280] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1031.2511920928955, \"sum\": 1031.2511920928955, \"min\": 1031.2511920928955}, \"setuptime\": {\"count\": 1, \"max\": 12.392997741699219, \"sum\": 12.392997741699219, \"min\": 12.392997741699219}}, \"EndTime\": 1538164169.953191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164169.950651}\n",
      "\u001b[0m\n",
      "\n",
      "2018-09-28 19:49:33 Uploading - Uploading generated training model\n",
      "2018-09-28 19:49:38 Completed - Training job completed\n",
      "Billable seconds: 47\n",
      "CPU times: user 356 ms, sys: 32 ms, total: 388 ms\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_kmeans.fit(sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  kmeans-2018-09-28-19-46-56-381\n",
      "Model saved at:  s3://rpanchum/kmeans_sm_0.5Mx20/kmeans-2018-09-28-19-46-56-381/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", sm_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", sm_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel DAAL Kmeans with 0.5Mx20 Synthetic Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://rpanchum/kmeans_sm_0.5Mx20\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'rpanchum' \n",
    "daal_0_5Mx20_data_key = 'kmeans_sm_0.5Mx20'\n",
    "\n",
    "daal_0_5Mx20_output_location = 's3://{}/{}'.format(bucket_name, sm_0_5Mx20_data_key)\n",
    "\n",
    "training_data_file = input_file_0_5Mx20\n",
    "print('training artifacts will be uploaded to: {}'.format(daal_0_5Mx20_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAL Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded at: s3://rpanchum/kmeans_sm_0.5Mx20/mlsd2_500000_20_20.csv\n",
      "CPU times: user 1.09 s, sys: 172 ms, total: 1.26 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "daal_0_5Mx20_data_location = sess.upload_data(training_data_file, bucket=bucket_name, key_prefix=daal_0_5Mx20_data_key)\n",
    "print (\"Training data uploaded at: \" + daal_0_5Mx20_data_location)\n",
    "\n",
    "daal_kmeans_image = '927702822156.dkr.ecr.us-west-2.amazonaws.com/daal-kmeans-sample:latest'\n",
    "\n",
    "daal_kmeans = sage.estimator.Estimator(image_name=daal_kmeans_image,\n",
    "                                       role=role,\n",
    "                                       train_instance_count=1,\n",
    "                                       train_instance_type='ml.c5.18xlarge',\n",
    "                                       output_path=daal_0_5Mx20_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       hyperparameters={'nClusters': 20,\n",
    "                                                        'initialCentroidMethod': 'plusPlusDense',\n",
    "                                                        'maxIterations': 100 } \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start DAAL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: daal-kmeans-sample-2018-09-28-19-50-10-745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 19:50:10 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-09-28 19:51:47 Downloading - Downloading input data\n",
      "2018-09-28 19:51:55 Training - Downloading the training image...\n",
      "Training image download completed. Training in progress..\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     Container setup completed, In Docker entrypoint - train... \u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     Default Hyperparameters loaded: \u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': 'defaultDense',\n",
      " 'maxIterations': 300,\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': 2,\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     Updated with user hyperparameters, Final Hyperparameters: \u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': u'plusPlusDense',\n",
      " 'maxIterations': u'100',\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': u'20',\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:39 INFO     Reading training data... \u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:40 INFO     Training Data Shape: (500000, 21)\u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:40 INFO     Starting DAAL Kmeans training...\u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:40 INFO     Training time in sec = 0.206146001816\u001b[0m\n",
      "\u001b[31m2018-09-28 19:52:40 INFO     Model saved at <open file '/opt/ml/model/daal-kmeans-model.npy', mode 'w' at 0x7fd53d37d270>\u001b[0m\n",
      "\n",
      "2018-09-28 19:52:44 Uploading - Uploading generated training model\n",
      "2018-09-28 19:52:49 Completed - Training job completed\n",
      "Billable seconds: 62\n",
      "CPU times: user 380 ms, sys: 12 ms, total: 392 ms\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daal_kmeans.fit(daal_0_5Mx20_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  daal-kmeans-sample-2018-09-28-19-50-10-745\n",
      "Model saved at:  s3://rpanchum/kmeans_sm_0.5Mx20/daal-kmeans-sample-2018-09-28-19-50-10-745/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", daal_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", daal_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Dataset 1 (0.5Mx20) Summary\n",
    "\n",
    "k=20, maxIterations=100\n",
    "\n",
    "Sagemaker Training Time Only: 0.69 sec  \n",
    "DAAL Training Time Only: 0.20 sec  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset 2: 4.8Mx38, k=20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-28 19:53:22--  https://s3-us-west-2.amazonaws.com/rpanchum/kmeans_datasets/4.8Mx38/mlsd1_4898430_38_20.csv\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.209.8\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.209.8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 435733898 (416M) [text/csv]\n",
      "Saving to: ‘mlsd1_4898430_38_20.csv’\n",
      "\n",
      "mlsd1_4898430_38_20 100%[===================>] 415.55M  95.4MB/s    in 4.5s    \n",
      "\n",
      "2018-09-28 19:53:27 (93.3 MB/s) - ‘mlsd1_4898430_38_20.csv’ saved [435733898/435733898]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O mlsd1_4898430_38_20.csv https://s3-us-west-2.amazonaws.com/rpanchum/kmeans_datasets/4.8Mx38/mlsd1_4898430_38_20.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0             1             2             3             4   \\\n",
      "count  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06   \n",
      "mean   4.833713e+01  1.843839e+03  1.091742e+03  5.716117e-06  6.487793e-04   \n",
      "std    7.223127e+02  9.414288e+05  6.450107e+05  2.390827e-03  4.284953e-02   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00  4.500000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    0.000000e+00  5.200000e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    0.000000e+00  1.032000e+03  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    5.832900e+04  1.379964e+09  1.309937e+09  1.000000e+00  3.000000e+00   \n",
      "\n",
      "                 5             6             7             8             9   \\\n",
      "count  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06   \n",
      "mean   7.961735e-06  1.243766e-02  3.205108e-05  1.435288e-01  8.088306e-03   \n",
      "std    7.215080e-03  4.688095e-01  7.299343e-03  3.503315e-01  3.856459e+00   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    1.400000e+01  7.700000e+01  5.000000e+00  1.000000e+00  7.479000e+03   \n",
      "\n",
      "           ...                 28            29            30            31  \\\n",
      "count      ...       4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06   \n",
      "mean       ...       2.336963e+02  1.884808e+02  7.483524e-01  3.058517e-02   \n",
      "std        ...       6.103406e+01  1.049925e+02  4.102526e-01  1.059904e-01   \n",
      "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%        ...       2.550000e+02  4.900000e+01  4.100000e-01  0.000000e+00   \n",
      "50%        ...       2.550000e+02  2.550000e+02  1.000000e+00  0.000000e+00   \n",
      "75%        ...       2.550000e+02  2.550000e+02  1.000000e+00  4.000000e-02   \n",
      "max        ...       2.550000e+02  2.550000e+02  1.000000e+00  1.000000e+00   \n",
      "\n",
      "                 32            33            34            35            36  \\\n",
      "count  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06  4.898430e+06   \n",
      "mean   6.047089e-01  6.450152e-03  1.780691e-01  1.778579e-01  5.792641e-02   \n",
      "std    4.938553e-01  4.081934e-02  3.905994e-01  3.911031e-01  2.300195e-01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "\n",
      "                 37  \n",
      "count  4.898430e+06  \n",
      "mean   5.765594e-02  \n",
      "std    2.300605e-01  \n",
      "min    0.000000e+00  \n",
      "25%    0.000000e+00  \n",
      "50%    0.000000e+00  \n",
      "75%    0.000000e+00  \n",
      "max    1.000000e+00  \n",
      "\n",
      "[8 rows x 38 columns]\n",
      "Training data shape:  (4898430, 38)\n",
      "CPU times: user 1min 46s, sys: 8.15 s, total: 1min 54s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file_4_8Mx38 = \"mlsd1_4898430_38_20.csv\"\n",
    "data = pd.read_csv(input_file_4_8Mx38, header=None, dtype=np.float32)\n",
    "print (data.describe())\n",
    "\n",
    "train_set = np.array(data)\n",
    "print (\"Training data shape: \", train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://rpanchum/kmeans_sm_4.8Mx38\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'rpanchum' \n",
    "sm_4_8Mx38_data_key = 'kmeans_sm_4.8Mx38'\n",
    "sm_4_8Mx38_data_location = 's3://{}/{}'.format(bucket_name, sm_4_8Mx38_data_key)\n",
    "sm_4_8Mx38_output_location = 's3://{}/{}'.format(bucket_name, sm_4_8Mx38_data_key)\n",
    "\n",
    "print('training artifacts will be uploaded to: {}'.format(sm_4_8Mx38_output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RecordSet format of training data as required by SM Kmeans...\n",
      "(<class 'sagemaker.amazon.amazon_estimator.RecordSet'>, {'s3_data': 's3://rpanchum/kmeans_sm_4.8Mx38/KMeans-2018-09-28-19-53-51-236/.amazon.manifest', 'feature_dim': 38, 'num_records': 4898430, 's3_data_type': 'ManifestFile', 'channel': 'train'})\n",
      "CPU times: user 2min 34s, sys: 3.17 s, total: 2min 37s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker import KMeans\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm_kmeans = KMeans(role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.18xlarge',\n",
    "                    output_path=sm_4_8Mx38_output_location,\n",
    "                    k=20,\n",
    "                    center_factor=1,\n",
    "                    init_method='kmeans++',\n",
    "                    max_iterations=100,\n",
    "                    data_location=sm_4_8Mx38_data_location)\n",
    "\n",
    "print ('Building RecordSet format of training data as required by SM Kmeans...')\n",
    "sm_kmeans_records = sm_kmeans.record_set(train_set)\n",
    "print (sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Sagemaker Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kmeans-2018-09-28-19-56-41-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 19:56:42 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training......\n",
      "2018-09-28 19:58:52 Downloading - Downloading input data\n",
      "2018-09-28 19:59:08 Training - Downloading the training image...\n",
      "2018-09-28 19:59:39 Uploading - Uploading generated training model\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'k': u'20', u'force_dense': u'True', u'init_method': u'kmeans++', u'feature_dim': u'38', u'local_lloyd_max_iter': u'100', u'extra_center_factor': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'38', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'100', u'_kvstore': u'auto', u'k': u'20', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 WARNING 139688635033408] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Using default worker.\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Create Store: local\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] nvidia-smi took: 0.0251231193542 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'1', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'38', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'kmeans++', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'100', u'_kvstore': u'auto', u'k': u'20', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:172: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:122: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1538164770.258288, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164770.258259}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 10: Short term msd 56134656.858871. Long term msd 61600806.255307\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 20: Short term msd 15850053.174876. Long term msd 28706163.209981\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 30: Short term msd 17448832.509471. Long term msd 19130552.248917\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 40: Short term msd 17013065.155604. Long term msd 17228955.255896\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 50: Short term msd 1556318759.372604. Long term msd 1672519753.969754\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 60: Short term msd 905532860.149241. Long term msd 1243095536.145761\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 70: Short term msd 1875352460.851033. Long term msd 1784428531.320458\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:30 INFO 139688635033408] Iter 80: Short term msd 3187080323.035531. Long term msd 2692385226.235881\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 90: Short term msd 2584200227765.732910. Long term msd 3729351486655.703125\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 100: Short term msd 278397241990.252441. Long term msd 1300797721601.106445\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 110: Short term msd 30075096263.385784. Long term msd 453787614453.983337\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 120: Short term msd 3229293947.330007. Long term msd 158225006875.030518\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 130: Short term msd 346746927.744114. Long term msd 55169535481.683792\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 140: Short term msd 37235787.877399. Long term msd 19236416496.321869\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 150: Short term msd 11752473031.202028. Long term msd 12831173727.446392\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 160: Short term msd 2188975469.795639. Long term msd 5342829965.005961\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 170: Short term msd 5850008673.669496. Long term msd 6827553296.476733\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 180: Short term msd 1041805635.500881. Long term msd 2675055531.037398\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 190: Short term msd 111979216.049810. Long term msd 932822634.035535\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:31 INFO 139688635033408] Iter 200: Short term msd 12099665.357043. Long term msd 325312517.994304\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 210: Short term msd 2602259161.371862. Long term msd 2563268798.805283\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 220: Short term msd 378330915.328541. Long term msd 1036513630.839033\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 230: Short term msd 40626902.747728. Long term msd 361412859.584164\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 240: Short term msd 4366623.540604. Long term msd 126020029.029568\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 250: Short term msd 472939.905152. Long term msd 43943455.924937\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 260: Short term msd 1552051.564957. Long term msd 17010147.599911\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 270: Short term msd 3140524089.280726. Long term msd 1623430908.682125\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 280: Short term msd 49346263016.694130. Long term msd 28854030031.062798\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 290: Short term msd 17042336413417.455078. Long term msd 19437291615423.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 300: Short term msd 1830035704350.876221. Long term msd 6777541133023.078125\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 310: Short term msd 196498647217.307556. Long term msd 2363182514383.307129\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 320: Short term msd 21098930068.025650. Long term msd 823990828777.123779\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:32 INFO 139688635033408] Iter 330: Short term msd 2265520579.363305. Long term msd 287307866633.482178\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 340: Short term msd 243292266.743389. Long term msd 100178083820.865891\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 350: Short term msd 26152103.770559. Long term msd 34929959292.068161\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 360: Short term msd 2832970.665746. Long term msd 12179342104.877968\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 370: Short term msd 326522.264345. Long term msd 4246690557.558960\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 380: Short term msd 54122.002934. Long term msd 1480743519.538146\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 390: Short term msd 22665.040063. Long term msd 516315762.401915\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 400: Short term msd 17476.494659. Long term msd 180039256.076221\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 410: Short term msd 15385.355217. Long term msd 62785753.173227\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 420: Short term msd 13849.482759. Long term msd 21901015.183037\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 430: Short term msd 12554.471990. Long term msd 7644553.353092\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 440: Short term msd 11435.024180. Long term msd 2672908.609086\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 450: Short term msd 10460.097161. Long term msd 938772.506733\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 460: Short term msd 9604.310786. Long term msd 333562.478023\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:33 INFO 139688635033408] Iter 470: Short term msd 8851.101336. Long term msd 122051.057041\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 480: Short term msd 8181.599498. Long term msd 47867.834277\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 490: Short term msd 7585.770305. Long term msd 21615.722603\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 500: Short term msd 7052.115690. Long term msd 12116.342724\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 510: Short term msd 6581.916954. Long term msd 8498.733746\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 520: Short term msd 6169.501312. Long term msd 6971.350763\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 530: Short term msd 5783.856759. Long term msd 6188.258074\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 540: Short term msd 5429.106850. Long term msd 5684.807127\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 550: Short term msd 5105.277402. Long term msd 5299.094268\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 560: Short term msd 4809.457086. Long term msd 4972.651756\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 570: Short term msd 4538.201381. Long term msd 4682.801103\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 580: Short term msd 4289.780522. Long term msd 4420.528475\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 590: Short term msd 4060.987241. Long term msd 4180.578430\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:34 INFO 139688635033408] Iter 600: Short term msd 3849.878165. Long term msd 3959.868920\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 610: Short term msd 3655.140481. Long term msd 3756.496490\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 620: Short term msd 3474.078058. Long term msd 3567.982168\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 630: Short term msd 3306.510593. Long term msd 3393.487536\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 640: Short term msd 3151.054816. Long term msd 3231.666771\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 650: Short term msd 3006.480455. Long term msd 3081.420271\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 660: Short term msd 2871.440379. Long term msd 2941.296480\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 670: Short term msd 2745.438885. Long term msd 2810.565882\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 680: Short term msd 341908516.899938. Long term msd 170955945.059429\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 690: Short term msd 101630773825.738388. Long term msd 102759275703.635544\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 700: Short term msd 10913302346.308138. Long term msd 35831068495.448311\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 710: Short term msd 1171810889.943114. Long term msd 12493524018.689417\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:35 INFO 139688635033408] Iter 720: Short term msd 125826525.494954. Long term msd 4356225569.289138\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 730: Short term msd 13514691.357437. Long term msd 1518924981.625925\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 740: Short term msd 450116103.083004. Long term msd 927318613.771615\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 750: Short term msd 48334748.461576. Long term msd 323338861.687930\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 760: Short term msd 5199801.753382. Long term msd 112749214.753466\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 770: Short term msd 562353.452853. Long term msd 39316166.710400\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 780: Short term msd 64528.914584. Long term msd 13711700.155994\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 790: Short term msd 50375748334981.929688. Long term msd 45389371829461.125000\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 800: Short term msd 5409055065335.544922. Long term msd 15826295568040.900391\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 810: Short term msd 580793129436.631348. Long term msd 5518288244684.870117\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 820: Short term msd 62362440870.366524. Long term msd 1924108322811.908203\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 830: Short term msd 6696358887.490759. Long term msd 670895266312.159180\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:36 INFO 139688635033408] Iter 840: Short term msd 719249607.204415. Long term msd 233926885903.321228\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 850: Short term msd 77453608.311978. Long term msd 81565426213.166809\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 860: Short term msd 8533007.086610. Long term msd 28440264046.227528\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 870: Short term msd 1124877.443156. Long term msd 9916659626.643478\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 880: Short term msd 322005.476781. Long term msd 3457872686.206547\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 890: Short term msd 228776.826161. Long term msd 1205827785.104110\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 900: Short term msd 1627923234.826551. Long term msd 1743517300.311081\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 910: Short term msd 2973858895.466014. Long term msd 2583103451.044385\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 920: Short term msd 362064033.494214. Long term msd 962365612.835904\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 930: Short term msd 38880177.076473. Long term msd 335558968.790596\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 940: Short term msd 4178895.464587. Long term msd 117005232.799795\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 950: Short term msd 452867.965473. Long term msd 40800230.507154\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:37 INFO 139688635033408] Iter 960: Short term msd 309364324.512498. Long term msd 299649444.542717\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] Iter 970: Short term msd 493930934.778823. Long term msd 580350549.403173\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] processed a total of 4898430 examples\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 980, \"sum\": 980.0, \"min\": 980}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 980, \"sum\": 980.0, \"min\": 980}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 4898430, \"sum\": 4898430.0, \"min\": 4898430}, \"Total Batches Seen\": {\"count\": 1, \"max\": 981, \"sum\": 981.0, \"min\": 981}, \"Total Records Seen\": {\"count\": 1, \"max\": 4903430, \"sum\": 4903430.0, \"min\": 4903430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 4898430, \"sum\": 4898430.0, \"min\": 4898430}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1538164778.117886, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1538164770.258526}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] #throughput_metric: host=algo-1, train throughput=623254.661872 records/second\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 WARNING 139688635033408] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] shrinking 20 centers into 20\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #0. Current mean square distance 5126.699707\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #1. Current mean square distance 20217.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #2. Current mean square distance 8019.719727\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #3. Current mean square distance 5126.699707\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #4. Current mean square distance 20217.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #5. Current mean square distance 5126.699707\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #6. Current mean square distance 20217.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #7. Current mean square distance 20217.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #8. Current mean square distance 20217.894531\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] local kmeans attempt #9. Current mean square distance 5126.699707\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] finished shrinking process. Mean Square Distance = 5127\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] #quality_metric: host=algo-1, train msd <loss>=5126.69970703\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] batch data loading with context took: 72.4288%, (5.642038 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] predict compute msd took: 9.8086%, (0.764071 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] gradient: cluster center took: 4.6315%, (0.360786 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] update state and report convergance took: 2.7392%, (0.213379 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] compute all data-center distances: inner product took: 2.0040%, (0.156106 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] compute all data-center distances: point norm took: 1.9024%, (0.148192 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] collect from kv store took: 1.6038%, (0.124936 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] gradient: cluster size  took: 1.5149%, (0.118004 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] gradient: one_hot took: 1.4416%, (0.112300 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] compute all data-center distances: center norm took: 0.9014%, (0.070217 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] splitting centers key-value pair took: 0.8706%, (0.067816 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] predict minus dist took: 0.1521%, (0.011847 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] update set-up time took: 0.0010%, (0.000080 secs)\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] TOTAL took: 7.7897734642\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 225.22783279418945, \"sum\": 225.22783279418945, \"min\": 225.22783279418945}, \"initialize.time\": {\"count\": 1, \"max\": 31.6469669342041, \"sum\": 31.6469669342041, \"min\": 31.6469669342041}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.16307830810546875, \"sum\": 0.16307830810546875, \"min\": 0.16307830810546875}, \"update.time\": {\"count\": 1, \"max\": 7859.251022338867, \"sum\": 7859.251022338867, \"min\": 7859.251022338867}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.23412704467773438, \"sum\": 0.23412704467773438, \"min\": 0.23412704467773438}, \"_shrink.time\": {\"count\": 1, \"max\": 224.47919845581055, \"sum\": 224.47919845581055, \"min\": 224.47919845581055}}, \"EndTime\": 1538164778.343791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164770.207484}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/28/2018 19:59:38 INFO 139688635033408] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 8200.932025909424, \"sum\": 8200.932025909424, \"min\": 8200.932025909424}, \"setuptime\": {\"count\": 1, \"max\": 12.59303092956543, \"sum\": 12.59303092956543, \"min\": 12.59303092956543}}, \"EndTime\": 1538164778.34621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1538164778.343862}\n",
      "\u001b[0m\n",
      "\n",
      "2018-09-28 19:59:44 Completed - Training job completed\n",
      "Billable seconds: 53\n",
      "CPU times: user 436 ms, sys: 32 ms, total: 468 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_kmeans.fit(sm_kmeans_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  kmeans-2018-09-28-19-56-41-770\n",
      "Model saved at:  s3://rpanchum/kmeans_sm_4.8Mx38/kmeans-2018-09-28-19-56-41-770/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", sm_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", sm_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel DAAL Kmeans with 4.8Mx38 Synthetic Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://rpanchum/kmeans_daal_4.8Mx38\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'rpanchum' \n",
    "daal_4_8Mx38_data_key = 'kmeans_daal_4.8Mx38'\n",
    "\n",
    "daal_4_8Mx38_output_location = 's3://{}/{}'.format(bucket_name, daal_4_8Mx38_data_key)\n",
    "\n",
    "training_data_file = input_file_4_8Mx38\n",
    "print('training artifacts will be uploaded to: {}'.format(daal_4_8Mx38_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAL Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded at: s3://rpanchum/kmeans_daal_4.8Mx38/mlsd1_4898430_38_20.csv\n",
      "CPU times: user 3.47 s, sys: 580 ms, total: 4.05 s\n",
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "daal_4_8Mx38_data_location = sess.upload_data(training_data_file, bucket=bucket_name, key_prefix=daal_4_8Mx38_data_key)\n",
    "print (\"Training data uploaded at: \" + daal_4_8Mx38_data_location)\n",
    "\n",
    "daal_kmeans_image = '927702822156.dkr.ecr.us-west-2.amazonaws.com/daal-kmeans-sample:latest'\n",
    "\n",
    "daal_kmeans = sage.estimator.Estimator(image_name=daal_kmeans_image,\n",
    "                                       role=role,\n",
    "                                       train_instance_count=1,\n",
    "                                       train_instance_type='ml.c5.18xlarge',\n",
    "                                       output_path=daal_4_8Mx38_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       hyperparameters={'nClusters': 20,\n",
    "                                                        'initialCentroidMethod': 'plusPlusDense',\n",
    "                                                        'maxIterations': 100 } \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start DAAL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: daal-kmeans-sample-2018-09-28-20-00-29-976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-28 20:00:30 Starting - Starting the training job...\n",
      "Launching requested ML instances.........\n",
      "Preparing the instances for training......\n",
      "2018-09-28 20:03:19 Downloading - Downloading input data\n",
      "2018-09-28 20:03:31 Training - Downloading the training image......\n",
      "Training image download completed. Training in progress.\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     Container setup completed, In Docker entrypoint - train... \u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     Default Hyperparameters loaded: \u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': 'defaultDense',\n",
      " 'maxIterations': 300,\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': 2,\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     Updated with user hyperparameters, Final Hyperparameters: \u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     {'accuracyThreshold': 0.0001,\n",
      " 'assignFlag': True,\n",
      " 'distanceType': 'euclidean',\n",
      " 'gamma': 1.0,\n",
      " 'initialCentroidMethod': u'plusPlusDense',\n",
      " 'maxIterations': u'100',\n",
      " 'method': 'defaultDense',\n",
      " 'nClusters': u'20',\n",
      " 'nRounds': 5,\n",
      " 'oversamplingFactor': 0.5}\u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:16 INFO     Reading training data... \u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:26 INFO     Training Data Shape: (4898430, 38)\u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:29 INFO     Starting DAAL Kmeans training...\u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:31 INFO     Training time in sec = 2.9277279377\u001b[0m\n",
      "\u001b[31m2018-09-28 20:04:32 INFO     Model saved at <open file '/opt/ml/model/daal-kmeans-model.npy', mode 'w' at 0x7f71f9861270>\u001b[0m\n",
      "\n",
      "2018-09-28 20:04:37 Uploading - Uploading generated training model\n",
      "2018-09-28 20:04:42 Completed - Training job completed\n",
      "Billable seconds: 84\n",
      "CPU times: user 512 ms, sys: 36 ms, total: 548 ms\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "daal_kmeans.fit(daal_4_8Mx38_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  daal-kmeans-sample-2018-09-28-20-00-29-976\n",
      "Model saved at:  s3://rpanchum/kmeans_daal_4.8Mx38/daal-kmeans-sample-2018-09-28-20-00-29-976/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Job Name: \", daal_kmeans.latest_training_job.name)\n",
    "print(\"Model saved at: \", daal_kmeans.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Dataset 1 ( 4.8Mx38, k=20 ) Summary\n",
    "\n",
    "k=20, maxIterations=100\n",
    "\n",
    "Sagemaker Training Time Only: 7.78 sec  \n",
    "DAAL Training Time Only: 2.92 sec  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
